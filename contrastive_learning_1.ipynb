{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!cp -r ../input/custom-data-generator/custom_data_generator* ./\nimport custom_data_generator","metadata":{"execution":{"iopub.status.busy":"2022-01-13T22:16:10.162765Z","iopub.execute_input":"2022-01-13T22:16:10.163094Z","iopub.status.idle":"2022-01-13T22:16:10.930735Z","shell.execute_reply.started":"2022-01-13T22:16:10.163054Z","shell.execute_reply":"2022-01-13T22:16:10.929750Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2022-01-13T22:16:10.932594Z","iopub.execute_input":"2022-01-13T22:16:10.932825Z","iopub.status.idle":"2022-01-13T22:16:10.937358Z","shell.execute_reply.started":"2022-01-13T22:16:10.932798Z","shell.execute_reply":"2022-01-13T22:16:10.936407Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\nimport glob\nimport tensorflow as tf\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras import layers, models, Sequential\nfrom tensorflow.keras.preprocessing import image_dataset_from_directory\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nfrom tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n\nfrom tensorflow.keras.applications.resnet50 import ResNet50\n\nfrom custom_data_generator.custom_image_data_generator import CustomImageDataGenerator\n\nfrom sklearn.metrics import classification_report , f1_score\n\n","metadata":{"execution":{"iopub.status.busy":"2022-01-13T22:16:10.938784Z","iopub.execute_input":"2022-01-13T22:16:10.939610Z","iopub.status.idle":"2022-01-13T22:16:10.948319Z","shell.execute_reply.started":"2022-01-13T22:16:10.939573Z","shell.execute_reply":"2022-01-13T22:16:10.947449Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"learning_rate = 0.01 #try and error\nbatch_size = 64\ninput_shape  = (256, 256, 3) #try and error\ntemperature = 0.1 #try and error\noutput_dim = 256\n# data_path  = \"camera 2\"\nthreshold = 0.85","metadata":{"execution":{"iopub.status.busy":"2022-01-13T22:16:10.951098Z","iopub.execute_input":"2022-01-13T22:16:10.951482Z","iopub.status.idle":"2022-01-13T22:16:10.959476Z","shell.execute_reply.started":"2022-01-13T22:16:10.951446Z","shell.execute_reply":"2022-01-13T22:16:10.958701Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"tf.config.list_physical_devices('GPU')","metadata":{"execution":{"iopub.status.busy":"2022-01-13T22:16:10.960711Z","iopub.execute_input":"2022-01-13T22:16:10.961554Z","iopub.status.idle":"2022-01-13T22:16:10.969573Z","shell.execute_reply.started":"2022-01-13T22:16:10.961495Z","shell.execute_reply":"2022-01-13T22:16:10.968786Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"folders_names = os.listdir(r\"../input/driver-dataset/train/train\")\nprint(folders_names)\n","metadata":{"execution":{"iopub.status.busy":"2022-01-13T22:16:10.971119Z","iopub.execute_input":"2022-01-13T22:16:10.971711Z","iopub.status.idle":"2022-01-13T22:16:10.982670Z","shell.execute_reply.started":"2022-01-13T22:16:10.971675Z","shell.execute_reply":"2022-01-13T22:16:10.981701Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"markdown","source":"Data Prep","metadata":{}},{"cell_type":"code","source":"def get_train_schema(dir_name, normal_str, csv_file_name, view=\"\"):\n    \"\"\"\n    generate csv file contains two columns: \n        \"Path\": the path for each image\n        \"Label\": the label of each image\n        \n    # Arguments\n        dir_name: path for the dataset directory which contains the classes folders\n        normal_str: the starting string of the normal data folders \n        csv_file_name: Name of the generated csv file \n        view: One of \"front_depth\", \"front_IR\", \"top_depth\", \"top_IR\" or \"\" if we use AUC dataset\n    \"\"\"\n    folders_names = os.listdir(dir_name)\n    \n    path_lst = []\n    label_lst = []\n    \n    for folder in folders_names[2:]:\n        label = 0  if folder.startswith(normal_str) else 1\n        paths = glob.glob(f'{dir_name}/{folder}/{view}/*')\n        labels = [label] * len(paths)\n\n        path_lst.extend(paths)\n        label_lst.extend(labels)\n        \n    data_tuples = list(zip(path_lst,label_lst))\n    df = pd.DataFrame(data_tuples, columns=['Path','Label'])   \n\n    df.to_csv(f\"{csv_file_name}.csv\", header=True, index=False)\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2022-01-13T22:16:10.984210Z","iopub.execute_input":"2022-01-13T22:16:10.984468Z","iopub.status.idle":"2022-01-13T22:16:10.994383Z","shell.execute_reply.started":"2022-01-13T22:16:10.984435Z","shell.execute_reply":"2022-01-13T22:16:10.993501Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"def get_test_schema(dir_name, normal_str, csv_file_name, view=\"\"):\n    \"\"\"\n    generate csv file contains two columns: \n        \"Path\": the path for each image\n        \"Label\": the label of each image\n        \n    # Arguments\n        dir_name: path for the dataset directory which contains the classes folders\n        normal_str: the starting string of the normal data folders \n        csv_file_name: Name of the generated csv file \n        view: One of \"front_depth\", \"front_IR\", \"top_depth\", \"top_IR\" or \"\" if we use AUC dataset\n    \"\"\"\n    folders_names = os.listdir(dir_name)\n    \n    path_lst = []\n    label_lst = []\n    \n    for folder in folders_names:\n        label = 0  if folder.startswith(normal_str) else 1\n        paths = glob.glob(f'{dir_name}/{folder}/{view}/*')\n        labels = [label] * len(paths)\n\n        path_lst.extend(paths)\n        label_lst.extend(labels)\n        \n    data_tuples = list(zip(path_lst,label_lst))\n    df = pd.DataFrame(data_tuples, columns=['Path','Label'])   \n\n    df.to_csv(f\"{csv_file_name}.csv\", header=True, index=False)\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2022-01-13T22:16:10.996290Z","iopub.execute_input":"2022-01-13T22:16:10.996485Z","iopub.status.idle":"2022-01-13T22:16:11.006741Z","shell.execute_reply.started":"2022-01-13T22:16:10.996456Z","shell.execute_reply":"2022-01-13T22:16:11.006010Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"get_train_schema(\"../input/driver-dataset/train/train\", \"c0\", \"Camera 2_train_Schema\")\n","metadata":{"execution":{"iopub.status.busy":"2022-01-13T22:16:11.008610Z","iopub.execute_input":"2022-01-13T22:16:11.010603Z","iopub.status.idle":"2022-01-13T22:16:11.040911Z","shell.execute_reply.started":"2022-01-13T22:16:11.010567Z","shell.execute_reply":"2022-01-13T22:16:11.040152Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"get_test_schema(\"../input/driver-dataset/test/test\", \"c0\", \"Camera 2_test_Schema\")\n\n","metadata":{"execution":{"iopub.status.busy":"2022-01-13T22:16:11.045056Z","iopub.execute_input":"2022-01-13T22:16:11.045635Z","iopub.status.idle":"2022-01-13T22:16:11.062632Z","shell.execute_reply.started":"2022-01-13T22:16:11.045602Z","shell.execute_reply":"2022-01-13T22:16:11.061938Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"train_data_schema_cam2 = pd.read_csv(\"Camera 2_train_Schema.csv\",dtype=str )\ntest_data_schema_cam2 = pd.read_csv(\"Camera 2_test_Schema.csv\",dtype=str)\n\ntrain_data_schema_cam2.sort_values(\"Label\", inplace=True)\ntest_data_schema_cam2.sort_values(\"Label\", inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-13T22:16:11.063904Z","iopub.execute_input":"2022-01-13T22:16:11.064317Z","iopub.status.idle":"2022-01-13T22:16:11.080259Z","shell.execute_reply.started":"2022-01-13T22:16:11.064282Z","shell.execute_reply":"2022-01-13T22:16:11.079572Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"train_data_schema_cam2","metadata":{"execution":{"iopub.status.busy":"2022-01-13T22:16:11.081438Z","iopub.execute_input":"2022-01-13T22:16:11.081762Z","iopub.status.idle":"2022-01-13T22:16:11.093505Z","shell.execute_reply.started":"2022-01-13T22:16:11.081726Z","shell.execute_reply":"2022-01-13T22:16:11.092470Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"code","source":"test_data_schema_cam2","metadata":{"execution":{"iopub.status.busy":"2022-01-13T22:16:11.095352Z","iopub.execute_input":"2022-01-13T22:16:11.096062Z","iopub.status.idle":"2022-01-13T22:16:11.111022Z","shell.execute_reply.started":"2022-01-13T22:16:11.096026Z","shell.execute_reply":"2022-01-13T22:16:11.110275Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"(train_data_schema_cam2[\"Label\"] == \"1\").sum()","metadata":{"execution":{"iopub.status.busy":"2022-01-13T22:16:11.114024Z","iopub.execute_input":"2022-01-13T22:16:11.114230Z","iopub.status.idle":"2022-01-13T22:16:11.121141Z","shell.execute_reply.started":"2022-01-13T22:16:11.114206Z","shell.execute_reply":"2022-01-13T22:16:11.120291Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"code","source":"(train_data_schema_cam2[\"Label\"] == \"0\").sum()","metadata":{"execution":{"iopub.status.busy":"2022-01-13T22:16:11.122663Z","iopub.execute_input":"2022-01-13T22:16:11.123570Z","iopub.status.idle":"2022-01-13T22:16:11.130835Z","shell.execute_reply.started":"2022-01-13T22:16:11.123532Z","shell.execute_reply":"2022-01-13T22:16:11.129897Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"code","source":"train_normal_count_cam2 = (train_data_schema_cam2[\"Label\"] == \"0\").sum()\ntrain_normal_count_cam2","metadata":{"execution":{"iopub.status.busy":"2022-01-13T22:16:11.132211Z","iopub.execute_input":"2022-01-13T22:16:11.133163Z","iopub.status.idle":"2022-01-13T22:16:11.140677Z","shell.execute_reply.started":"2022-01-13T22:16:11.133126Z","shell.execute_reply":"2022-01-13T22:16:11.139847Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"#Create train generator\ntrain_datagen =  CustomImageDataGenerator(\n    rotation_range=20,#try_and_error\n    channel_shift_range=20,#try_and_error\n    horizontal_flip=True,\n    preprocessing_function = preprocess_input#scale input pixels between -1 and 1.\n)\n\n#Read the training data using train generator\ntrain_ds = train_datagen.flow_from_dataframe(\n    dataframe=train_data_schema_cam2,\n    directory=\".\",\n    x_col=\"Path\",\n    y_col=\"Label\",\n#     subset=\"training\",\n    batch_size=batch_size,\n    seed=42,\n#     shuffle=True,\n    class_mode=\"binary\",\n    target_size=input_shape[0:-1],\n    positive_n = train_normal_count_cam2,\n)","metadata":{"execution":{"iopub.status.busy":"2022-01-13T22:16:11.142120Z","iopub.execute_input":"2022-01-13T22:16:11.142636Z","iopub.status.idle":"2022-01-13T22:16:11.588175Z","shell.execute_reply.started":"2022-01-13T22:16:11.142599Z","shell.execute_reply":"2022-01-13T22:16:11.587427Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"code","source":"#Create test generator\ntest_datagen = CustomImageDataGenerator(preprocessing_function = preprocess_input)\n\n\n#Read the testing data using test generator\ntest_ds = test_datagen.flow_from_dataframe(\n    dataframe=test_data_schema_cam2,\n    directory=\".\",\n    x_col=\"Path\",\n    y_col=\"Label\",\n    seed = 42,\n    batch_size=batch_size,\n    target_size=input_shape[0:-1],\n    class_mode='binary', \n    shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2022-01-13T22:16:11.589331Z","iopub.execute_input":"2022-01-13T22:16:11.590015Z","iopub.status.idle":"2022-01-13T22:16:11.759140Z","shell.execute_reply.started":"2022-01-13T22:16:11.589959Z","shell.execute_reply":"2022-01-13T22:16:11.758409Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"code","source":"  # base_encoder\ndef create_encoder(input_shape):\n    mobilenet = MobileNetV2(\n        input_shape=input_shape, include_top=False, weights='imagenet',\n        input_tensor=None\n    )\n#     mobilenet.trainable = False ## Not trainable weights\n    \n    inputs = tf.keras.Input(shape=input_shape)\n    x = mobilenet(inputs)\n    x = layers.Conv2D(512, kernel_size=1)(x)\n    outputs = layers.GlobalAvgPool2D()(x)\n    model = tf.keras.Model(inputs=inputs, outputs=outputs, name=\"base-encoder\")\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-01-13T22:16:11.760475Z","iopub.execute_input":"2022-01-13T22:16:11.761235Z","iopub.status.idle":"2022-01-13T22:16:11.767508Z","shell.execute_reply.started":"2022-01-13T22:16:11.761197Z","shell.execute_reply":"2022-01-13T22:16:11.766811Z"},"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"code","source":"# projection_head\ndef add_projection_head(encoder, input_shape):\n    inputs = tf.keras.Input(shape=input_shape)\n    features = encoder(inputs)\n    x = layers.Dense(512, activation=\"relu\")(features)#here it takes 1280 vec_length but in paper it takes 512\n    x = layers.Dense(output_dim, activation=None)(x)\n    outputs = layers.Lambda(lambda  v: tf.math.l2_normalize(v,axis=1))(x)\n    \n    model = tf.keras.Model(\n        inputs=inputs, outputs=outputs, name=\"base-encoder_with_projection-head\"\n    )\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-01-13T22:16:11.769826Z","iopub.execute_input":"2022-01-13T22:16:11.770054Z","iopub.status.idle":"2022-01-13T22:16:11.778859Z","shell.execute_reply.started":"2022-01-13T22:16:11.770025Z","shell.execute_reply":"2022-01-13T22:16:11.778064Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"code","source":"import tensorflow.keras.backend as K\n\n#Loss Function\nclass SupervisedContrastiveLoss(tf.keras.losses.Loss):\n    def __init__(self, temperature=1, name=None):\n        super(SupervisedContrastiveLoss, self).__init__(name=name)\n        self.temperature = temperature\n\n    def __call__(self, labels, feature_vectors, sample_weight=None):\n        \n#         tf.print(K.shape(feature_vectors))\n        # Normalize feature vectors\n#         feature_vectors = tf.math.l2_normalize(feature_vectors, axis=1)\n        \n        \n        #separate normal and anomaly examples   \n        n_idxs = tf.reshape(tf.where(labels == 0)[:,0], [-1, 1])\n        a_idxs = tf.reshape(tf.where(labels == 1)[:,0], [-1, 1])\n        \n        n_vectors = tf.gather_nd(feature_vectors, n_idxs)\n        a_vectors = tf.gather_nd(feature_vectors, a_idxs)\n        # Compute logits\n        n_scores = tf.divide(\n            tf.matmul(n_vectors, tf.transpose(n_vectors)),\n            self.temperature,\n        )\n        \n        a_n_scores = tf.divide(\n            tf.matmul(n_vectors, tf.transpose(a_vectors)),\n            self.temperature,\n        )\n        pos_logits = tf.exp(n_scores)\n        neg_logits = tf.exp(a_n_scores)\n        \n        #compute loss\n        denominator = pos_logits + tf.reduce_sum(neg_logits, axis=-1, keepdims=True)\n        loss_steps = -1 * tf.math.log((pos_logits / denominator))\n        loss_steps = tf.linalg.set_diag(loss_steps , tf.zeros(K.shape(loss_steps)[0])) # remove values for i==j(diagonal)\n#         tf.print(\"1\",loss_steps)\n        k = tf.cast(K.shape(n_scores), tf.float32)[0]\n        k = tf.math.maximum(k, 2) # prevent divide by zero, when the batch contains no or one normal photos\n#         tf.print(\"2\",loss_steps)\n        loss = (1/(k*(k-1))) * tf.reduce_sum(loss_steps)\n        return loss\n","metadata":{"execution":{"iopub.status.busy":"2022-01-13T22:16:11.780949Z","iopub.execute_input":"2022-01-13T22:16:11.781841Z","iopub.status.idle":"2022-01-13T22:16:11.794748Z","shell.execute_reply.started":"2022-01-13T22:16:11.781803Z","shell.execute_reply":"2022-01-13T22:16:11.794012Z"},"trusted":true},"execution_count":90,"outputs":[]},{"cell_type":"code","source":"#build the model\n\nbase_encoder = create_encoder(input_shape)\n\nencoder_with_projection_head = add_projection_head(base_encoder, input_shape)\n\n\nlr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n    initial_learning_rate=1e-2,\n    decay_steps=1000,\n    decay_rate=0.9)\n\n\nencoder_with_projection_head.compile(\n    optimizer=tf.keras.optimizers.SGD(learning_rate=lr_schedule),\n#                                       momentum=0.9,\n                                     \n    loss=SupervisedContrastiveLoss(temperature),\n    \n    \n    #loss = tf.keras.metrics.binary_crossentropy\n)\n\nencoder_with_projection_head.summary()\n\n","metadata":{"execution":{"iopub.status.busy":"2022-01-13T22:16:11.796075Z","iopub.execute_input":"2022-01-13T22:16:11.796545Z","iopub.status.idle":"2022-01-13T22:16:13.623967Z","shell.execute_reply.started":"2022-01-13T22:16:11.796507Z","shell.execute_reply":"2022-01-13T22:16:13.623135Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"code","source":"checkpoint = tf.keras.callbacks.ModelCheckpoint('BestModelCam2{epoch:02d}.h5', period=50) \nhistory = encoder_with_projection_head.fit(train_ds, epochs=150, batch_size=batch_size, callbacks=[checkpoint] , )","metadata":{"execution":{"iopub.status.busy":"2022-01-13T22:16:13.625590Z","iopub.execute_input":"2022-01-13T22:16:13.626108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# is this ok since layers.Lambda has no weights, so no need for fitting?\n#build test model\ndef get_test_model(encoder, input_shape):\n    \n    inputs = tf.keras.Input(shape=input_shape)\n    features = encoder(inputs)\n    outputs = layers.Lambda(lambda  v: tf.math.l2_normalize(v,axis=1))(features)\n    model = tf.keras.Model(\n        inputs=inputs, outputs=outputs, name=\"test_model\"\n    )\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict_class(test_data, normal_template_vector, therashold):\n    \"\"\"\n    test_data: each row represent feature vector of a photo\n    \n    \"\"\"\n    sim = np.dot(test_data, normal_template_vector)\n    return (sim < therashold).astype(int) # true for an anomaly ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"normal_data_schema = train_data_schema_cam2.loc[train_data_schema_cam2[\"Label\"] == \"0\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # read normal images\n\nnormal_ds = test_datagen.flow_from_dataframe(\n    dataframe=normal_data_schema,\n    directory=\".\",\n    seed = 42,\n    x_col=\"Path\",\n    y_col=\"Label\",\n    class_mode=\"categorical\",\n    target_size=input_shape[0:-1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get normal_template_vector\ntest_model = get_test_model(base_encoder, input_shape)\n\nnormal_v = test_model.predict(normal_ds)\n\nnormal_template_vector = np.mean(normal_v, axis=0, keepdims=True).reshape(-1,1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_v = test_model.predict(test_ds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result = predict_class(test_v, normal_template_vector,therashold=0.54)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"m = tf.keras.metrics.AUC()\nm.update_state(y_true, result)\nm.result().numpy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.save(\"Normal Vector11.npy\", normal_template_vector)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loaded_array = np.load(\"Normal Vector.npy\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_true = test_data_schema_cam2[\"Label\"].astype('int')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"m = tf.keras.metrics.AUC()\nm.update_state(y_true, result)\nm.result().numpy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"m = tf.keras.metrics.Accuracy()\nm.update_state(y_true, result)\nm.result().numpy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"m = tf.keras.metrics.Recall()\nm.update_state(y_true, result)\nm.result().numpy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f1_score(y_true, result))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"m = classification_report(y_true, result)\nprint(m)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport seaborn as sns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cm = (confusion_matrix(y_true, result))\nprint(cm)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cm_df = pd.DataFrame(cm,\n                    index=['Normal' , 'Anomaly'],\n                    columns=['Normal' , 'Anomaly']\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(8, 6))\nsns.heatmap(cm_df, annot=True)\nplt.title('Confusion Matrix')\nplt.ylabel('Actal Values')\nplt.xlabel('Predicted Values')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(8, 6))\n\nplt.plot(history.history['loss'], 'r')\nplt.legend(['Loss'])\nplt.xlabel('Epochs', color = 'b')\nplt.ylabel('Loss', color = 'b')\n\nplt.title('Training Loss vs Epochs' , color = 'b')\nplt.show();","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_model.save('Contrastive Model11')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_model.save('Contrastive Final Model11.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}