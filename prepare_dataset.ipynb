{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Using cached pandas-1.3.5-cp38-cp38-win_amd64.whl (10.2 MB)\n",
      "Collecting python-dateutil>=2.7.3\n",
      "  Using cached python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
      "Collecting pytz>=2017.3\n",
      "  Using cached pytz-2021.3-py2.py3-none-any.whl (503 kB)\n",
      "Collecting numpy>=1.17.3; platform_machine != \"aarch64\" and platform_machine != \"arm64\" and python_version < \"3.10\"\n",
      "  Using cached numpy-1.21.5-cp38-cp38-win_amd64.whl (14.0 MB)\n",
      "Collecting six>=1.5\n",
      "  Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Installing collected packages: six, python-dateutil, pytz, numpy, pandas\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.15.0\n",
      "    Uninstalling six-1.15.0:\n",
      "      Successfully uninstalled six-1.15.0\n",
      "  Attempting uninstall: python-dateutil\n",
      "    Found existing installation: python-dateutil 2.8.1\n",
      "    Uninstalling python-dateutil-2.8.1:\n",
      "      Successfully uninstalled python-dateutil-2.8.1\n",
      "  Attempting uninstall: pytz\n",
      "    Found existing installation: pytz 2020.1\n",
      "    Uninstalling pytz-2020.1:\n",
      "      Successfully uninstalled pytz-2020.1\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.21.5\n",
      "    Uninstalling numpy-1.21.5:\n",
      "      Successfully uninstalled numpy-1.21.5\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.3.0\n",
      "    Uninstalling pandas-1.3.0:\n",
      "      Successfully uninstalled pandas-1.3.0\n",
      "Successfully installed numpy-1.21.5 pandas-1.3.5 python-dateutil-2.8.2 pytz-2021.3 six-1.16.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
      "\n",
      "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
      "\n",
      "tensorflow 2.6.0 requires numpy~=1.19.2, but you'll have numpy 1.21.5 which is incompatible.\n",
      "tensorflow 2.6.0 requires six~=1.15.0, but you'll have six 1.16.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install --force-reinstall pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_schema(dir_name, normal_str, csv_file_name, view=\"\"):\n",
    "    \"\"\"\n",
    "    generate csv file contains two columns: \n",
    "        \"Path\": the path for each image\n",
    "        \"Label\": the label of each image\n",
    "        \n",
    "    # Arguments\n",
    "        dir_name: path for the dataset directory which contains the classes folders\n",
    "        normal_str: the starting string of the normal data folders \n",
    "        csv_file_name: Name of the generated csv file \n",
    "        view: One of \"front_depth\", \"front_IR\", \"top_depth\", \"top_IR\" or \"\" if we use AUC dataset\n",
    "    \"\"\"\n",
    "    folders_names = os.listdir(dir_name)\n",
    "    \n",
    "    path_lst = []\n",
    "    label_lst = []\n",
    "    \n",
    "    for folder in folders_names:\n",
    "        label = 0  if folder.startswith(normal_str) else 1\n",
    "        paths = glob.glob(f'{dir_name}/{folder}/{view}/*')\n",
    "        labels = [label] * len(paths)\n",
    "\n",
    "        path_lst.extend(paths)\n",
    "        label_lst.extend(labels)\n",
    "        \n",
    "    data_tuples = list(zip(path_lst,label_lst))\n",
    "    df = pd.DataFrame(data_tuples, columns=['Path','Label'])   \n",
    "\n",
    "    df.to_csv(f\"{csv_file_name}.csv\", header=True, index=False)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_data_schema(\"Dataset/Tester1\", \"normal\", \"train_DAD_Schema\", \"/top_depth/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_data_schema(\"train\", \"c0\", \"Camera 2_train_Schema\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_data_schema(\"test\", \"c0\", \"Camera 2_test_Schema\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extract top_depth Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folders_names = os.listdir(\"train\")\n",
    "# print(folders_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_lst = []\n",
    "# label_lst = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for folder in folders_names[:7]:\n",
    "#     label = 0  if folder.startswith(\"c0\") else 1\n",
    "#     paths =  glob.glob(f'train/{folder}/*')\n",
    "#     labels = [label] * len(paths)\n",
    "    \n",
    "#     path_lst.extend(paths)\n",
    "#     label_lst.extend(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_tuples = list(zip(path_lst,label_lst)) # list of each product name and price paired together\n",
    "# df = pd.DataFrame(data_tuples, columns=['Path','Label'])   \n",
    "\n",
    "\n",
    "# df.to_csv(\"train_DAD_Schema.csv\", header=True, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extract Camera2 Dataset"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9']\n"
     ]
    }
   ],
   "source": [
    "folders_names = os.listdir(\"train\")\n",
    "print(folders_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path_lst = []\n",
    "train_label_lst = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in folders_names[:6]:\n",
    "    label = 0  if folder.startswith(\"c0\") else 1\n",
    "    paths = glob.glob(f'train/{folder}/*')\n",
    "    labels = [label] * len(paths)\n",
    "    \n",
    "    train_path_lst.extend(paths)\n",
    "    train_label_lst.extend(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tuples = list(zip(train_path_lst,train_label_lst)) # list of each product name and price paired together\n",
    "df = pd.DataFrame(data_tuples, columns=['Path','Label'])   \n",
    "\n",
    "\n",
    "df.to_csv(\"Camera 2_train_Schema.csv\", header=True, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9']\n"
     ]
    }
   ],
   "source": [
    "folders_names = os.listdir(\"test\")\n",
    "print(folders_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path_lst = []\n",
    "test_label_lst = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in folders_names[:6]:\n",
    "    label = 0  if folder.startswith(\"c0\") else 1\n",
    "    paths = glob.glob(f'test/{folder}/*')\n",
    "    labels = [label] * len(paths)\n",
    "    \n",
    "    test_path_lst.extend(paths)\n",
    "    test_label_lst.extend(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tuples = list(zip(test_path_lst,test_label_lst)) # list of each product name and price paired together\n",
    "df = pd.DataFrame(data_tuples, columns=['Path','Label'])   \n",
    "\n",
    "\n",
    "df.to_csv(\"Camera 2_test_Schema.csv\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
